{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YpbnPF_MEv4h"
   },
   "source": [
    "# Mitigating Bias with MinDiff Model Remediation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "- Learn the concept of equal opportunity fairness.\n",
    "- Learn how to apply MinDiff method to a TensorFlow model to mitigate bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yMcQGRPHnjP9"
   },
   "source": [
    "## Introduction\n",
    "In this notebook, we’ll train a text classifier to identify written content that could be considered toxic or harmful, and apply MinDiff to remediate some fairness concerns. In our workflow, we will:\n",
    "1.   Train and evaluate our baseline model’s performance on text containing references to sensitive groups.\n",
    "2.   Improve performance on any underperforming groups by training with MinDiff.\n",
    "3.   Evaluate the new model’s performance on our chosen metric.\n",
    "\n",
    "The purpose of this notebook is to demonstrate the usage of the MinDiff technique with a very minimal workflow, not to lay out a principled approach to fairness in machine learning. As such, our evaluation will only focus on one sensitive category and a single metric. We also don’t address potential shortcomings in the dataset, nor tune our configurations in this notebook. \n",
    "\n",
    "In a production setting, you would want to approach each of these with rigor. For more information on evaluating for fairness, see [this guide](https://www.tensorflow.org/responsible_ai/fairness_indicators/guide/guidance).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SlyU3HZpob8i"
   },
   "source": [
    "Import all necessary components, including MinDiff in TensorFlow Model Remediation library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JYLW8UIsIMrE",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_model_remediation.min_diff as md\n",
    "from tensorflow_model_remediation.tools.tutorials_utils import (\n",
    "    min_diff_keras_utils,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zPkyRv5_ozdC"
   },
   "source": [
    "We use a utility function to download the preprocessed data and prepare the labels to match the model’s output shape. The function also downloads the data as TFRecords to make later evaluation quicker. Alternatively, you may convert the Pandas DataFrame into TFRecords with any available utility conversion function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-Hw5HdppwuBs",
    "outputId": "23fdc373-69f3-4dcc-bb1c-e0457193d9ee",
    "tags": []
   },
   "outputs": [],
   "source": [
    "(\n",
    "    data_train,\n",
    "    data_validate,\n",
    "    _,\n",
    "    _,\n",
    "    _,\n",
    ") = min_diff_keras_utils.download_and_process_civil_comments_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `comment_text` column has text feature and `toxicity` has the label which represents whether the text is toxic or not (1 or 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_train[data_train[\"toxicity\"] == 1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.histplot(data_train.toxicity.apply(str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LGum4JXSo-Qu"
   },
   "source": [
    "It looks like the positive (toxic) data is much fewer than the negative (non-toxic) data.\n",
    "\n",
    "We define a few constants. Note that the batch size here is chosen arbitrarily, but in a production setting you would need to tune it for best performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ular7EPMU_Y1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "TEXT_FEATURE = \"comment_text\"\n",
    "LABEL = \"toxicity\"\n",
    "BATCH_SIZE = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We convert the training data from pandas dataframe to tf.data, and create a generator that yields a batch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also convert our Pandas DataFrames into Tensorflow Datasets.  Note that unlike the Keras model API for Pandas DataFrames, using Datasets means that we need to provide the model’s input features and labels together in one Dataset. Here we provide the `'comment_text'` as an input feature and reshape the label to match the model's expected output.\n",
    "\n",
    "We batch the Dataset at this stage, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_dataset(df, batch_size):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(\n",
    "        (\n",
    "            df[TEXT_FEATURE].values,\n",
    "            df[LABEL].values,\n",
    "        )\n",
    "    ).batch(batch_size)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "dataset_train_main = make_dataset(data_train, BATCH_SIZE)\n",
    "dataset_valid_main = make_dataset(data_validate, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D_r-uFyQpbkW"
   },
   "source": [
    "## Define and train the baseline model\n",
    "\n",
    "Let's define a simple baseline model to classify the text toxicity. It is a simple Keras sequential model with an initial embedding and dense layers, outputting a toxicity prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KcRceFceKyE_",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    hub_url = \"https://tfhub.dev/google/tf2-preview/nnlm-en-dim128/1\"\n",
    "\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    # Embedding layer.\n",
    "    hub_layer = hub.KerasLayer(\n",
    "        hub_url, output_shape=[128], input_shape=[], dtype=tf.string\n",
    "    )\n",
    "    model.add(hub_layer)\n",
    "    model.add(tf.keras.layers.Dense(32, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "    return model\n",
    "\n",
    "\n",
    "baseline_model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 600
    },
    "id": "ID6DcW6e9vFM",
    "outputId": "7668a6aa-172c-4591-f7be-bc6e8ea2256e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "loss = tf.keras.losses.BinaryCrossentropy()\n",
    "baseline_model.compile(optimizer=optimizer, loss=loss, metrics=[\"accuracy\"])\n",
    "\n",
    "history = baseline_model.fit(\n",
    "    x=dataset_train_main, batch_size=BATCH_SIZE, epochs=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "valid_result = baseline_model.evaluate(dataset_valid_main)\n",
    "print(f\"Validation Accuracy: {valid_result[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "opFCpJjadf7g"
   },
   "source": [
    "## Prepare data splits for MinDiff\n",
    "\n",
    "To use MinDiff, we create two additional data splits:\n",
    "* A split for non-toxic examples referencing minority groups: In our case, this will include comments with references to our underperforming identity terms.  We don’t include some of the groups because there are too few examples, leading to higher uncertainty with wide confidence interval ranges.\n",
    "* A split for non-toxic examples referencing the majority group.\n",
    "\n",
    "It’s important to have sufficient examples belonging to the underperforming classes. Based on your model architecture, data distribution, and MinDiff configuration, the amount of data needed can vary significantly. In past applications, we have seen MinDiff work well with 5,000 examples in each data split.\n",
    "\n",
    "In our case, the groups in the minority splits have example quantities of 9,688 and 3,906. Note the class imbalances in the dataset; in practice, this could be cause for concern, but we won’t seek to address them in this notebook since our intention is just to demonstrate MinDiff.  \n",
    "\n",
    "We select only negative examples for these groups, so that MinDiff can optimize on getting these examples right. It may seem counterintuitive to carve out sets of ground truth *negative* examples if we’re primarily concerned with disparities in *false positive rate (FPR)*, but remember that a false positive prediction is a ground truth negative example that’s incorrectly classified as positive, which is the issue we’re trying to address."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1QilngDumRfI"
   },
   "source": [
    "### Create splits with DataFrame\n",
    "\n",
    "First, let's create the splits using pandas DataFrame.\n",
    "\n",
    "Note how we define majority and minority in this dataset. And we filter out positive example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jj4dychpyrqM",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_mindiff_datasets(df):\n",
    "    # Create masks for the sensitive and nonsensitive groups\n",
    "    minority_mask = df.religion.apply(\n",
    "        lambda x: any(religion in x for religion in (\"jewish\", \"muslim\"))\n",
    "    )\n",
    "    majority_mask = df.religion.apply(lambda x: x == \"['christian']\")\n",
    "\n",
    "    # Select nontoxic examples, so MinDiff will be able to reduce sensitive FP rate.\n",
    "    true_negative_mask = df[\"toxicity\"] == 0\n",
    "\n",
    "    data_sensitive = df[minority_mask & true_negative_mask]\n",
    "    data_nonsensitive = df[majority_mask & true_negative_mask]\n",
    "    return data_sensitive, data_nonsensitive\n",
    "\n",
    "\n",
    "data_train_sensitive, data_train_nonsensitive = create_mindiff_datasets(\n",
    "    data_train\n",
    ")\n",
    "data_valid_sensitive, data_valid_nonsensitive = create_mindiff_datasets(\n",
    "    data_validate\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we got two DataFrames for majority and minority."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_train_sensitive.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_train_nonsensitive.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yA4Kw9tsmopa"
   },
   "source": [
    "### Create MinDiff Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3lR_w3LHt6QK"
   },
   "source": [
    "Then, we wrap them in tf.data.Dataset using the `make_dataset` function defined above.\n",
    "\n",
    "Note that we tune the batch size selection the same way it is tuned for the baseline model, taking into account training speed and hardware considerations while balancing with model performance. Here we have chosen the same batch size for all three datasets but this is not a requirement, although it’s good practice to have the two MinDiff batch sizes be equivalent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_train_sensitive = make_dataset(data_train_sensitive, BATCH_SIZE)\n",
    "dataset_train_nonsensitive = make_dataset(data_train_nonsensitive, BATCH_SIZE)\n",
    "dataset_valid_sensitive = make_dataset(data_valid_sensitive, BATCH_SIZE)\n",
    "dataset_valid_nonsensitive = make_dataset(data_valid_nonsensitive, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model Evaluation\n",
    "### Check the Prediction distribution\n",
    "\n",
    "Now we have two data splits.\n",
    "\n",
    "Let's take a look at the prediction distribution for majority (nonsensitive) and minority (sensitive) classes using the baseline model.<br>\n",
    "Please remember that we only use negative examples, so ideally the predictions should be closer to 0.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def visualize_pred_histogram(model):\n",
    "    for (f, l), (non_f, non_l) in zip(\n",
    "        dataset_valid_sensitive.take(1), dataset_valid_nonsensitive.take(1)\n",
    "    ):\n",
    "        res = tf.squeeze(model(f))\n",
    "        non_res = tf.squeeze(model(non_f))\n",
    "        sns.histplot(\n",
    "            {\"sensitive\": res, \"nonsensitive\": non_res},\n",
    "            bins=50,\n",
    "            kde=True,\n",
    "            stat=\"density\",\n",
    "        )\n",
    "\n",
    "\n",
    "visualize_pred_histogram(baseline_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see a distribution difference between splits, and the minority dataset has lower confidence for the negative cases, that will lead to higher false positives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check FPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def false_positive_rate(y_true, y_pred, thresholds):\n",
    "    fp = tf.keras.metrics.FalsePositives(thresholds=thresholds)\n",
    "    fp.update_state(y_true, y_pred)\n",
    "    fp = fp.result().numpy()\n",
    "\n",
    "    tn = tf.keras.metrics.TrueNegatives(thresholds=thresholds)\n",
    "    tn.update_state(y_true, y_pred)\n",
    "    tn = tn.result().numpy()\n",
    "    return fp / (fp + tn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_fpr(model, thresholds=0.5):\n",
    "    nonsensitive_prediction = model.predict(\n",
    "        data_train_nonsensitive[TEXT_FEATURE], batch_size=BATCH_SIZE, verbose=3\n",
    "    )\n",
    "    sensitive_prediction = model.predict(\n",
    "        data_train_sensitive[TEXT_FEATURE], batch_size=BATCH_SIZE, verbose=3\n",
    "    )\n",
    "\n",
    "    nonsensitive_fpr = false_positive_rate(\n",
    "        data_train_nonsensitive[LABEL].values,\n",
    "        nonsensitive_prediction,\n",
    "        thresholds=thresholds,\n",
    "    )\n",
    "    sensitive_fpr = false_positive_rate(\n",
    "        data_train_sensitive[LABEL].values,\n",
    "        sensitive_prediction,\n",
    "        thresholds=thresholds,\n",
    "    )\n",
    "\n",
    "    print(f\"Nonsensitive FPR: {nonsensitive_fpr:>5.5f}\")\n",
    "    print(f\"Sensitive FPR: {sensitive_fpr:>10.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "compute_fpr(baseline_model, thresholds=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the baseline model is performing differently on different splits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CRG6SHR8ryMV"
   },
   "source": [
    "## Define and Train the MinDiff Model\n",
    "\n",
    "Now, we’ll try to improve the FPR for underperforming religious groups. We’ll attempt to do so using [MinDiff](https://arxiv.org/abs/1910.11779), a remediation technique that seeks to balance error rates across slices of your data by penalizing disparities in performance during training. When we apply MinDiff, model performance may degrade slightly on other slices. As such, our goals with MinDiff will be:\n",
    "*   Improved performance for underperforming groups\n",
    "*   Limited degradation for other groups and overall performance\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XRGvjZ8VuBvz"
   },
   "source": [
    "To train with MinDiff, we have to follow these steps:\n",
    "\n",
    "- Define the model architecture\n",
    "- Wrap it in a MinDiffModel with a corresponding `loss` and `loss_weight`.  \n",
    "- Compile the model normally (using the regular non-MinDiff loss) and fit to train. \n",
    "\n",
    "For the loss definition, we use 1.5 as the default `loss_weight`, which means how we prioritize the MinDiff loss over the primary cross entropy loss, but this is a parameter that needs to be tuned for your use case, since it depends on your model and product requirements.<br>\n",
    "You can experiment with changing the value to see how it impacts the model, noting that increasing it pushes the performance of the minority and majority groups closer together but may come with more pronounced tradeoffs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "original_model = build_model()\n",
    "\n",
    "min_diff_loss = md.losses.MMDLoss()\n",
    "min_diff_weight = 1.5\n",
    "\n",
    "min_diff_model = md.keras.MinDiffModel(\n",
    "    original_model, min_diff_loss, min_diff_weight\n",
    ")\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "loss = tf.keras.losses.BinaryCrossentropy()\n",
    "min_diff_model.compile(optimizer=optimizer, loss=loss, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "And we also defines the dataset that will be passed to the MinDiffModel during training.\n",
    "\n",
    "Here we repeat the dataset so that we can train on the same amount as the base model for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 686
    },
    "id": "xutVGl9fyikP",
    "outputId": "c6c7759b-9ba6-415c-e84b-dbc4b81f36d3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "min_diff_dataset = md.keras.utils.input_utils.pack_min_diff_data(\n",
    "    original_dataset=dataset_train_main,\n",
    "    sensitive_group_dataset=dataset_train_sensitive,\n",
    "    nonsensitive_group_dataset=dataset_train_nonsensitive,\n",
    ")\n",
    "\n",
    "min_diff_dataset = min_diff_dataset.repeat(\n",
    "    int(\n",
    "        dataset_train_main.cardinality()\n",
    "        // dataset_train_sensitive.cardinality()\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's execute the MinDiff training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = min_diff_model.fit(min_diff_dataset, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "doJhbIKVwQdp"
   },
   "source": [
    "Next we evaluate the results.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MinDiff Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the result by visualizing the prediction distribution again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "visualize_pred_histogram(min_diff_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JObiq-mVwUzL"
   },
   "source": [
    "This looks much better sicce the distributions are closer compared to the baseline model.\n",
    "\n",
    "Let's check the FPR as we did for the baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "compute_fpr(min_diff_model, thresholds=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FPRs for sensitive and nonsensitive datasets are also very close!\n",
    "\n",
    "In a production setting, we have to pick a threshold to ensure that the model behavior meets launch standards.<br>\n",
    "This threshold may be different from the one you selected for the baseline model. Try selecting false positive rate with threshold 0.300."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "compute_fpr(min_diff_model, thresholds=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2024 Google Inc. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "min_diff_keras.ipynb",
   "provenance": []
  },
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m129",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m129"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
